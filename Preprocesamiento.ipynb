{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![HenryLogo](https://d31uz8lwfmyn8g.cloudfront.net/Assets/logo-henry-white-lg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocesamiento de datos**\n",
    "\n",
    "El preprocesamiento es uno de los estadios más importantes en el flujo de trabajo de un data scientist. Suele demandar, en promedio, entre el 60% y 70% de nuestro tiempo. La distinción entre un buen y un mal modelo de Machine Learning, antes que por la elección de un algoritmo específico, estará dada por un correcto preprocesamiento de datos.\n",
    "\n",
    "> ### *\"Garbage in, garbage out\"*\n",
    "\n",
    "Si queremos un modelo predictivo de calidad, debemos darle datos de calidad. Podemos elegir el algoritmo más sofisticado y complejo, optimizar los hiperparámetros tratando de encontrar las mejores combinaciones posibles, pero si al modelo lo alimentamos con datos que carecen de sentido, no podemos esperar que sus predicciones sí lo tengan.\n",
    "\n",
    "### `Etapas`:\n",
    "\n",
    "1. Valores faltantes\n",
    "\n",
    "1. Valores atípicos\n",
    "\n",
    "3. Escalado/normalización\n",
    "\n",
    "4. Codificación de variables categóricas\n",
    "\n",
    "5. Selección de atributos relevantes\n",
    "\n",
    "6. Ingeniería de features\n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Valores faltantes**\n",
    "\n",
    "Generalmente, y de manera errónea, lo primero que buscamos responder en esta estapa es ¿qué técnica utilizo para imputar los valores faltantes del dataset? o ¿qué porcentaje de valores faltantes es suficiente para dropear esas filas?\n",
    "\n",
    "El proceso que debemos seguir arranca con una pregunta inicial bastante diferente y trascendental en todo lo que devenga.\n",
    "\n",
    "**`¿Por qué hay valores faltantes?`**\n",
    "\n",
    "Para responder esta pregunta, tenemos tres grandes paradigmas bien diferenciados que nos darán una noción del escenario en que estamos situados.\n",
    "\n",
    "+ MCAR\n",
    "\n",
    "+ MAR\n",
    "\n",
    "+ MNAR\n",
    "\n",
    "#### **`MCAR`**\n",
    "\n",
    "*Missing Completely At Random*.\n",
    "\n",
    "La probabilidad de tener un dato faltante es la misma para todas las instancias. La causa de los datos que faltan no está relacionada directamente con los datos.\n",
    "\n",
    "Ejemplo: fallas en el instrumento de medición o errores en la carga de los datos. Supongamos el caso de un encuestador que visita hogares para completar un cuestionario con preguntas cerradas. Recibe las respuestas, por parte del encuestado, de cada pregunta que va realizando, pero se olvida de marcar el casillero correspondiente en alguna pregunta. Cuando esos datos sean cargados en el sistema, tendremos valores faltantes en esos campos donde el encuestador cometió el error de no indicar la respuesta del encuestado. En efecto, la falta de valores en algunos campos no responde a ninguna razón que se desprenda de los datos o las preguntas realizadas -podría pasar que algunas preguntas sean evitadas adrede por los encuestados por connotaciones sociales, políticas, etc.- sino por cuestiones completamente azarosas.\n",
    "\n",
    "#### **`MAR`**\n",
    "\n",
    "*Missing At Random*. Si la probabilidad de que falten datos es la misma solo dentro de los grupos definidos por los datos observados, entonces los datos faltan al azar. La causa de los datos que faltan está relacionada con otras variables.\n",
    "\n",
    "Ejemplo: un encuestador realiza una EPH (Encuesta Permanente de Hogares). Se observa que varios encuestados no responden ante la pregunta de cuánto es su salario o remuneración laboral percibida. Al observar la totalidad de los datos finales de nuestro dataset, notamos que la mayoría de los valores faltantes en este campo -**salario**- están directamente relacionados con el barrio al que pertenece el encuestado. Entonces, podemos determinar que, si la encuesta se realiza en CABA, los ciudadanos de los barrios más pudientes (Recoleta, Palermo, Belgrano o Puerto Madero) indican cuánto es su salario -casi en todos los casos superior a la media de CABA- en una EPH. Por el contrario, los encuestados ubicados en barrios marginales no responden esa pregunta de la encuesta. O bien podría darse la situación inversa a la planteada.\n",
    "\n",
    "Para pensar, una técnica que consista en imputar los valores faltantes del campo **salario** con alguna medida de tendencia central, como la media, ¿distorsionaría nuestros datos? ¿afectaría la representatividad?\n",
    "\n",
    "Este tipo de faltantes se presenta con más frecuencia que el caso visto anteriormente.\n",
    "\n",
    "#### **`MNAR`**\n",
    "\n",
    "*Missing Not At Random*. Se llega a este caso por descarte, cuando la presencia de valores faltantes en nuestro dataset no responde a ninguno de los dos paradigmas enunciados supra. Es el caso más complejo de identificar. A grandes rasgos, este tipo de valores nulos puede responder a dos razones:\n",
    "\n",
    "1. El motivo de esta ausencia de valores se relaciona con datos no observados -es común que, en ensayos clínicos, si un tratamiento particular causa molestias, los pacientes sean más propensos a abandonar el estudio y, dado que se busca medir la eficacia de cada tratamiento, tengamos faltantes no aleatorios-.\n",
    "\n",
    "2. La ausencia de valores responde directamente a la variable que queremos medir -cuando indicábamos que un encuestado evita responder una pregunta por la incomodidad que ella pueda generarle-. \n",
    "\n",
    "*Resumen de los tres mecanismos generadores de valores faltantes:*\n",
    "\n",
    "<img src = \"https://cjasn.asnjournals.org/content/clinjasn/early/2014/02/06/CJN.10141013/F2.large.jpg?width=800&height=600&carousel=1\" height = 200>\n",
    "\n",
    "Ahora sí, pasemos a las técnicas que existen para lidiar con los valores faltantes. De lo visto recientemente, se desprende que la estrategia utilizada para tratar los valores nulos estará, en gran medida, condicionada por la razón de que esos valores sean, precisamente, nulos. Es decir, el mecanismo que los está generando.\n",
    "\n",
    "### **¿Qué hacemos con los valores faltantes?**\n",
    "\n",
    "+ ***Eliminar los datos con problemas***: por fila -puede sesgar el resultado-. Por columna -podemos perder información relevante-.\n",
    "\n",
    "+ ***Imputación***: rellenamos con estadísticos obtenidos de los datos que sí tenemos. También se puede imputar teniendo en cuenta los valores de otros atributos -por ejemplo, en vez de imputar los faltantes del campo salario con la media total, lo hacemos con la media de cada barrio-. Otra posibilidad, para realizar la imputación, es elaborar un modelo de Machine Learning que prediga el valor de ese dato faltante.\n",
    "\n",
    "+ ***Agregar una variable dummy***: por atributo, para indicar si hay un valor faltante. Esa variable nos indica si ese dato es imputado.\n",
    "\n",
    "\n",
    "- - -\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Valores atípicos**\n",
    "\n",
    "También denominados outliers o valores extremos. Son aquellos datos que difieren significativamente del resto de las observaciones. \n",
    "\n",
    "**`¿Por qué existen?`**\n",
    "\n",
    "+ Error del instrumento de medición\n",
    "\n",
    "+ Mezcla de distribuciones\n",
    "\n",
    "Un ejemplo del primer caso podría darse cuando se ingresa incorrectamente un valor a la hora de ser cargado. Mientras que el segundo caso se presenta cuando se trabaja con muestras o subpoblaciones que no son tan homogéneas como se creía a priori.\n",
    "\n",
    "Existe la posibilidad de que nos topemos con valores atípicos que no se inserten dentro de los dos casos enunciados. Allí, considerarlo o no como extremos, dependerá del problema con el que estemos tratando.\n",
    "\n",
    "En algunas oportunidades, detectar valores outliers será precisamente nuestro objetivo. Un ejemplo de ello puede ser la detección de una transacción fraudulenta con tarjeta de crédito o la identificación de una persona enferma dentro de un conjunto de personas sanas.\n",
    "\n",
    "Tenemos dos tipos de outliers: `univariado` y `multivariado`. El primer tipo se da cuando el outlier se desvía de los valores típicos de un feature. El segundo, cuando el outlier se desvía de los valores típicos que hay en la relación entre dos o más features.\n",
    "\n",
    "**`¿Cómo detectarlos?`**\n",
    "\n",
    "+ Visualización\n",
    "\n",
    "+ IQR\n",
    "\n",
    "+ 3σ \n",
    "\n",
    "Para detectar estos valores atípicos, podemos recurrir a las visualizaciones -a través de boxplots-, al rango intercuartílico o a la regla de las tres sigmas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "\n",
    "### **3. Escalado/normalización**\n",
    "\n",
    "Es probable que, en nuestro dataset, contemos con distintas variables, medidas en diferentes unidades y con distintas escalas. Esto puede confundir a los modelos de ML, ya que no entienden de unidades. En especial, a los modelos que trabajan con distancias -como KNN-. Para evitar esto, recurrimos al escalado de datos.\n",
    "\n",
    "Disponemos de tres formas para realizar el escalado:\n",
    "\n",
    "+ `Escalado mínimo-máximo`: se emplea cuando nuestra variable puede tomar valores entre un mínimo y un máximo bien delimitados.\n",
    "\n",
    "+ `Z-score`: también conocido como estandarización o normalización. Es la técnica más empleada. Es una medida de cuán lejos está un dato del promedio, medido en desviación estándar. También sirve para aplicar la regla de las 3 sigmas para detectar outliers, aplicando la máscara $|Z| > 3$.\n",
    "\n",
    "+ `Escalados no lineales`: se usa cuando el atributo no sigue una distribución lineal. En el caso de una distribución que siga una *ley de potencias*, se toma el logaritmo de los valores. Otro método es tomar la raíz cuadrada.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "\n",
    "### **4. Codificación de variables categóricas**\n",
    "\n",
    "Como sabemos, los modelos de Machine Learning solo entienden de números. Para ello, debemos transformar nuestros atributos del dataset que contengan datos cualitativos en cuantitativos.\n",
    "\n",
    "Ahora bien, supongamos que en un dataset tenemos una columna categórica que brinda información sobre la ciudad en la que vive una persona. Al hacer la conversión de la variable ***ciudad*** en numérica, nos quedaría, por ejemplo, el siguiente esquema:\n",
    "\n",
    "+ Mendoza = 0\n",
    "\n",
    "+ Santa Fe = 1\n",
    "\n",
    "+ Rosario = 2\n",
    "\n",
    "+ Paraná = 3\n",
    "\n",
    "Es decir, si la columna ***ciudad*** asume estos cuatro posibles valores -Mendoza, Santa Fe, Rosario o Paraná-, el proceso de codificación debería asignar los números de manera similar al esquema. Pero, ahora, el modelo estaría interpretando que Paraná es más importante que las demás ciudades, o que Santa Fe es más importante que Mendoza. \n",
    "\n",
    "En este punto, hay que introducir una diferenciación conceptual entre los dos subtipos de variables categóricas: `ordinales` y `nominales`. Mientras las primeras guardan una relación jerárquica entre sus datos, las segundas no. En las `variables ordinales` hay una relación de orden entre los distintos valores que asume -nivel de estudios, status socioeconómico, talle de ropa-. Por el contrario, en las `variables nominales` no es posible distinguir tal relación de orden -color de ojos, género, grupo sanguíneo-.\n",
    "\n",
    "Cuando tengamos que aplicar encoders, lo primero será identificar con qué subtipo de variable categórica estamos tratando. Si es una variable ordinal, usaremos un método que asigne un número a cada etiqueta -por ejemplo, para nivel de estudios: primario = 0, secundario = 1, universitario = 2, posgrado = 3-. Si es nominal, crearemos una variable dummy por cada posible valor de la variable. En el último caso hay que tener precaución porque, si la variable tiene muchos valores posibles, nuestro dataset crecerá demasiado.\n",
    "\n",
    "Para las variables ordinales podemos usar la clase `Label Encoder` de Scikit-learn. Para las variables nominales, `One Hot Encoder`.\n",
    "\n",
    "*Ejemplo de implementación de One Hot Encoder para la variable nominal color*:\n",
    "\n",
    "<img src = \"https://miro.medium.com/max/1400/1*ggtP4a5YaRx6l09KQaYOnw.png\" height = 250>\n",
    "\n",
    "\n",
    "Asimismo, hay otros aspectos que se pueden tratar en esta etapa del preprocesamiento. En algunas ocasiones, nos encontraremos en nuestro dataset con variables numéricas que pueden agruparse en grupos o rangos. Uno podría agrupar la columna ***edad*** por rangos etarios. También, podríamos agrupar las notas de un examen en calificaciones: malo, regular, bueno, muy bueno o excelente. A este proceso se lo conoce como `discretización` o `binning`. Aplicarlo puede ayudar a nuestro modelo a encontrar mejores patrones en los datos. A su vez, puede ayudar al data scientist a tener una mejor representación de la distribución de los datos.\n",
    "\n",
    "*Ejemplo de implementación de binning para la variable precio*:\n",
    "\n",
    "<img src = \"https://miro.medium.com/max/793/1*qJVjE6n5R0dfIxZfvsUFPw.png\" height = 350>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "634b189ffb04760e4d9c938c0422d278afb6e6e9858a0e6f9e273ab614bdcee1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
